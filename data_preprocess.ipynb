{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_size = (232, 348)\n",
    "datapath_orig = '../dataset/test'\n",
    "\n",
    "datapath2_tr =  '../dataset3/train/'\n",
    "datapath2_val = '../dataset3/val/'\n",
    "datapath2_tes = '../dataset3/test/'\n",
    "test_split = .025\n",
    "val_split = .041 + test_split\n",
    "\n",
    "#train\n",
    "sub_dirs = tf.gfile.Walk(datapath_orig)\n",
    "\n",
    "num_pics = 0\n",
    "root = True\n",
    "class_path = []\n",
    "img_paths = []\n",
    "for x in sub_dirs:\n",
    "    if root:\n",
    "        class_ids = x[1]\n",
    "        num_classes = len(x[1])\n",
    "        root = False\n",
    "        continue\n",
    "    class_path.append(x[0])\n",
    "    img_paths.append(x[2])\n",
    "    num_pics += len(x[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "num classes 8\n",
      "num pics 599\n",
      "['Boeing777', 'Airbus380', 'Airbus320', 'Boeing787', 'Boeing747', 'Boeing757', 'Boeing737', 'ERJ190']\n",
      "['../dataset/test/Boeing777', '../dataset/test/Airbus380', '../dataset/test/Airbus320', '../dataset/test/Boeing787', '../dataset/test/Boeing747', '../dataset/test/Boeing757', '../dataset/test/Boeing737', '../dataset/test/ERJ190']\n"
     ]
    }
   ],
   "source": [
    "print('train')\n",
    "print('num classes', num_classes)\n",
    "print('num pics', num_pics)\n",
    "print(class_ids)\n",
    "print(class_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train = np.zeros((num_pics, *target_size, 3))\n",
    "#y_train = np.zeros((num_pics, num_classes))\n",
    "\n",
    "#x_train = np.zeros((10, *target_size, 3))\n",
    "#y_train = np.zeros((10, num_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "ar_target = target_size[1]/target_size[0]\n",
    "#print(ar_target)\n",
    "pic_num = 0\n",
    "for i in range(num_classes): #num_classes\n",
    "    print(i)\n",
    "    current_dir = class_path[i]+'/'\n",
    "    pths = img_paths[i]\n",
    "    \n",
    "    save_tr = datapath2_tr+class_ids[i]+'/'\n",
    "    save_val = datapath2_val+class_ids[i]+'/'\n",
    "    save_tes = datapath2_tes+class_ids[i]+'/'\n",
    "    \n",
    "    if not os.path.exists(save_tr):\n",
    "        os.makedirs(save_tr)\n",
    "    if not os.path.exists(save_val):\n",
    "        os.makedirs(save_val)\n",
    "    if not os.path.exists(save_tes):\n",
    "        os.makedirs(save_tes)\n",
    "    \n",
    "    for k in range(len(pths)): #len(pths)\n",
    "        im = image.load_img(current_dir+pths[k])\n",
    "        \n",
    "        width, height = im.size\n",
    "        ar_im = width/height\n",
    "        \n",
    "        #print(height, width)\n",
    "        #print(ar_im)\n",
    "        \n",
    "        if ar_im > ar_target:\n",
    "            # Then crop the left and right edges:\n",
    "            new_width = int(ar_target * height)\n",
    "            offset = (width - new_width) / 2\n",
    "            resize = (offset, 0, width - offset, height)\n",
    "        else:\n",
    "            # ... crop the top and bottom:\n",
    "            new_height = int(width / ar_target)\n",
    "            offset = (height - new_height) / 2\n",
    "            resize = (0, offset, width, height - offset)\n",
    "        \n",
    "        im_resize = im.crop(resize).resize((target_size[1],target_size[0]), PIL.Image.BICUBIC)\n",
    "        \n",
    "        r = np.random.random()\n",
    "        if r < test_split:\n",
    "            im_resize.save(save_tes+pths[k], 'jpeg')\n",
    "        elif r < val_split:\n",
    "            im_resize.save(save_val+pths[k], 'jpeg')\n",
    "        else:\n",
    "            im_resize.save(save_tr+pths[k], 'jpeg')\n",
    "            \n",
    "        #width, height = im_resize.size\n",
    "        #print(height, width)\n",
    "        \n",
    "        \n",
    "        \n",
    "        #im_numpy = image.img_to_array(im_resize)\n",
    "        #y_cat = tf.keras.utils.to_categorical(i, num_classes)\n",
    "        \n",
    "        #x_train[pic_num,:,:,:] = im_numpy\n",
    "        #y_train[pic_num,:] = y_cat\n",
    "        #pic_num += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
